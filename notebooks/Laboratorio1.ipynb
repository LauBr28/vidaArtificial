{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68c54525-11d1-4299-86fc-d1c314313b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Laura Sofia Medina\n",
    "#Laura Alejandra Barrera "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "965d4069-5dd5-4ac9-b642-7b20e07345e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece] --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80a9343-b1e0-43fa-ae35-c56a9dfa4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce45c40c-3378-4021-8e56-f3f9568a49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9a15fe-8cf0-464b-b874-3af75a7da430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An√°lisis de Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e8e9c026-d5f8-474a-9079-22a51b7da27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POS', 'score': 0.9688300490379333}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "\n",
    "resultado = classifier(\"Me encanta el clima soleado.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb5a1872-45be-48c5-8fe1-bcba7559e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEG', 'score': 0.9765346050262451}]\n"
     ]
    }
   ],
   "source": [
    "resultado = classifier(\"Este servicio es terrible, no lo recomiendo en absoluto.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acdb8b5e-6e54-42c6-b373-3d0bcefcecc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEU', 'score': 0.814404308795929}]\n"
     ]
    }
   ],
   "source": [
    "resultado = classifier(\"El informe se entregar√° ma√±ana. No lo olvides\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faedeeff-e04a-4f10-993f-07a05b3359e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero-Shot Classification (Clasificaci√≥n de texto en categor√≠as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d7809bfd-fb9a-47b1-bd4b-a759776b6803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'El cambio clim√°tico es un problema global que requiere acciones inmediatas.', 'labels': ['medio ambiente', 'entretenimiento', 'tecnolog√≠a', 'salud'], 'scores': [0.9210784435272217, 0.03742522373795509, 0.0213615782558918, 0.020134741440415382]}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "resultado = classifier(\n",
    "    \"El cambio clim√°tico es un problema global que requiere acciones inmediatas.\",\n",
    "    candidate_labels=[\"medio ambiente\", \"tecnolog√≠a\", \"salud\",'entretenimiento'],\n",
    "    hypothesis_template=\"Este texto trata sobre {}.\"\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ed8375d-0ff5-4a15-94fa-e231006dc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generaci√≥n de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fc6811b-299f-48b6-8e36-79dca3411edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'En este curso aprender√°s sobre procesamiento de lenguaje natural, por lo que podr√°s disfrutar de un empleo. A partir de ahora, podr√°s disfrutar m√°s all√° del mundo f√≠sico y a partir del trabajo. A partir del trabajo y de la amistad. Una vez que'}, {'generated_text': 'En este curso aprender√°s sobre procesamiento de lenguaje natural, por lo que las personas no deben usar su propia jerga con frecuencia. \\n\\nComo en nuestro segundo a√±o aqu√≠, somos tan competentes. Sabemos que debemos aprender a usar los genes: informaci√≥n gen√©tica'}]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"DeepESP/gpt2-spanish\")\n",
    "\n",
    "resultado = generator(\n",
    "    \"En este curso aprender√°s sobre procesamiento de lenguaje natural, por lo que\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=2\n",
    ")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453e7b92-2ad7-4a1a-abb4-503bd65b071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'La inteligencia artificial est√° transformando su capacidad de razonar las estructuras mentales existentes? En un concepto particular, los conceptos morales no son comprendidos. Cuando consideramos que los principios morales eran esenciales para la pr√°ctica, la validez de la naturaleza √©tica cambia la realidad y la'}, {'generated_text': 'La inteligencia artificial est√° transformando en ficci√≥n material. Las experiencias f√≠sicas recientes y t√©cnicas de la inteligencia artificial han proporcionado tales conocimientos t√©cnicos. La observaci√≥n como el resultado de una exploraci√≥n en el espacio, la investigaci√≥n de los or√≠genes de la evoluci√≥n, la tecnolog√≠a de la'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = generator(\n",
    "    \"La inteligencia artificial est√° transformando\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=2\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93ef5348-96dd-4e65-bbde-3bb8de6c47cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'En el futuro, los robots ser√°n capaces de: ^^^^^^^a no ser√° f√°cil. La cosa no tiene soluci√≥n. \\n\\n‚ÄîY, por tanto, lo que les dar√° la respuesta la respuesta autom√°tica: \\n\\n‚ÄîLo que es seguro es: un ser humano muerto. Un ser humano muerto no puede vivir m√°s que en un mundo en el que las leyes son infinitas‚Ä¶ Hasta ahora no han pasado sin un fin. \\n\\n‚ÄîPero ¬øcon qu√© derecho? \\n'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = generator(\n",
    "    \"En el futuro, los robots ser√°n capaces de: \",\n",
    "    max_length=100,\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1435936-5ab0-427f-9522-693f1c62ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar el texto con la palabra m√°s probable (Fill-Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9e7b1db-22cb-4f7f-903f-784fae9e8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.08100215345621109, 'token': 3792, 'token_str': 'sociales', 'sequence': 'Este curso ense√±a sobre modelos sociales.'}, {'score': 0.06293947249650955, 'token': 6156, 'token_str': 'econ√≥micos', 'sequence': 'Este curso ense√±a sobre modelos econ√≥micos.'}, {'score': 0.027612948790192604, 'token': 3, 'token_str': '[UNK]', 'sequence': 'Este curso ense√±a sobre modelos.'}]\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "resultado = unmasker(\"Este curso ense√±a sobre modelos [MASK].\", top_k=3)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa939607-1fd6-425c-a2cf-732f16b94a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.19103224575519562, 'token': 22339, 'token_str': 'h√∫medo', 'sequence': 'El clima en la monta√±a es muy h√∫medo.'}, {'score': 0.1390262395143509, 'token': 7789, 'token_str': 'agradable', 'sequence': 'El clima en la monta√±a es muy agradable.'}, {'score': 0.12316220253705978, 'token': 7286, 'token_str': 'fr√≠o', 'sequence': 'El clima en la monta√±a es muy fr√≠o.'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = unmasker(\"El clima en la monta√±a es muy [MASK].\", top_k=3)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b9eef17-6e17-46c2-a5ba-0cc83a533239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.7116380333900452, 'token': 9823, 'token_str': 'c√°lculo', 'sequence': 'El c√°lculo es una rama de las matem√°ticas.'}, {'score': 0.06353506445884705, 'token': 4266, 'token_str': 'an√°lisis', 'sequence': 'El an√°lisis es una rama de las matem√°ticas.'}, {'score': 0.03623092547059059, 'token': 21403, 'token_str': 'c√≥mputo', 'sequence': 'El c√≥mputo es una rama de las matem√°ticas.'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = unmasker(\"El [MASK] es una rama de las matem√°ticas.\", top_k=3)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2b5b417-5bd6-48b7-acb9-8909e7505a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificar nombres propios en un texto (Entidades) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea25c014-6944-4dbe-92cb-af2c823938c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "/home/ubuntu/env/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': np.float32(0.99841666), 'word': 'Laura', 'start': 9, 'end': 14}, {'entity_group': 'LOC', 'score': np.float32(0.99990034), 'word': 'Madrid', 'start': 44, 'end': 50}]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\", grouped_entities=True)\n",
    "resultado = ner(\"Me llamo Laura y trabajo en una farmacia en Madrid.\")\n",
    "print(resultado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db0da9d8-2aa9-43d4-ad0d-4929499051b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'ORG', 'score': np.float32(0.99937135), 'word': 'Google', 'start': 0, 'end': 6}]\n"
     ]
    }
   ],
   "source": [
    "resultado = ner(\"Google anunci√≥ una nueva actualizaci√≥n de su sistema operativo.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f5d3a84-7a91-4d60-b431-a8efc7aa34fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'MISC', 'score': np.float32(0.9958806), 'word': 'Segunda Guerra Mundial', 'start': 3, 'end': 25}]\n"
     ]
    }
   ],
   "source": [
    "resultado = ner(\"La Segunda Guerra Mundial termin√≥ en 1945.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "626ccd51-6143-4c99-9c0f-0acc6dc9cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer respuestas a preguntas en un contexto dado (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7159d99-155d-42b5-9ffa-467f2c3ab954",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9999936819076538, 'start': 44, 'end': 49, 'answer': 'Par√≠s'}\n"
     ]
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\", model=\"PlanTL-GOB-ES/roberta-large-bne-sqac\")\n",
    "\n",
    "resultado = qa(\n",
    "    question=\"¬øCu√°l es la capital de Francia?\",\n",
    "    context=\"Francia es un pa√≠s de Europa. Su capital es Par√≠s.\"\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cf5c3bef-32b1-4b7a-a7ff-181989be5be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.9096104502677917, 'start': 19, 'end': 26, 'answer': 'en 1998'}\n"
     ]
    }
   ],
   "source": [
    "resultado = qa(\n",
    "    question=\"¬øCu√°ndo se fund√≥ Google?\",\n",
    "    context=\"Google fue fundado en 1998 por Larry Page y Sergey Brin. Es una de las empresas m√°s importantes del mundo.\"\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8b3b901-6543-45a9-ab97-99ecd0c3fa47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.998665452003479, 'start': 14, 'end': 18, 'answer': '1990'}\n"
     ]
    }
   ],
   "source": [
    "resultado = qa(\n",
    "    question=\"¬øQu√© edad tiene Juan?\",\n",
    "    context=\"Juan naci√≥ en 1990. Hoy es el a√±o 2025.\"\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b2c2f7e6-afc4-4259-828f-521b99cfcf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumen de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15e89ef8-1673-4b19-bcc9-032d025f63ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/ubuntu/env/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'La inteligencia artificial (IA) est√° transformando r√°pidamente el mundo en el que vivimos.'}]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "\n",
    "texto = \"\"\"\n",
    "La inteligencia artificial (IA) est√° transformando r√°pidamente el mundo en el que vivimos. \n",
    "En el sector salud, los algoritmos de IA permiten diagn√≥sticos m√°s precisos y tratamientos personalizados.\n",
    "Por ejemplo, sistemas de aprendizaje profundo analizan im√°genes m√©dicas para detectar enfermedades como el c√°ncer en etapas tempranas.\n",
    "\n",
    "En el √°mbito educativo, plataformas adaptativas utilizan IA para personalizar el aprendizaje seg√∫n las necesidades de cada estudiante, mejorando su rendimiento acad√©mico.\n",
    "En el transporte, los veh√≠culos aut√≥nomos impulsados por IA prometen reducir los accidentes de tr√°fico y optimizar el flujo del tr√°fico. \n",
    "Empresas como Tesla y Waymo lideran este campo, aunque a√∫n existen desaf√≠os t√©cnicos y regulatorios. \n",
    "Sin embargo, la IA tambi√©n plantea preocupaciones, como la p√©rdida de empleos debido a la automatizaci√≥n y los riesgos asociados con la privacidad de los datos.\n",
    "\n",
    "Adem√°s, la √©tica en la IA es un tema crucial. Los sistemas de IA pueden perpetuar sesgos si no se dise√±an adecuadamente, lo que podr√≠a llevar a decisiones injustas en √°reas como la contrataci√≥n o los pr√©stamos. \n",
    "Por ello, es esencial que los desarrolladores y reguladores trabajen juntos para garantizar que la IA se utilice de manera responsable y equitativa.\n",
    "\"\"\"\n",
    "\n",
    "resultado = summarizer(texto)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a15934b4-ba48-4b8b-a785-635d0befbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traducci√≥n de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02a1d320-28d0-4b13-8042-437f208a4e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/env/lib/python3.12/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Three sad tigers eat wheat in a trigal.'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-es-en\")\n",
    "\n",
    "resultado = translator(\"Tres tristes tigres comen trigo en un trigal.\")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26f69a65-3d7e-4058-b5d8-7eade9db7beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'The convolutional neural network is used in image processing.'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = translator(\"La red neuronal convolucional es utilizada en el procesamiento de im√°genes.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "270084a4-9cf0-4962-9cc3-f4147461e7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Being in the clouds.'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = translator(\"Estar en las nubes.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8eb9b74f-18f8-42c8-b70e-7edf981e770b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'translation_text': 'Climate change is a global problem that requires the cooperation of all countries to be resolved.'}]\n"
     ]
    }
   ],
   "source": [
    "resultado = translator(\"El cambio clim√°tico es un problema global que requiere la cooperaci√≥n de todos los pa√≠ses para ser resuelto.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8b54a-ec28-41d6-93e5-bf1239509ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
