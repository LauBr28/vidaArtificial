{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965d4069-5dd5-4ac9-b642-7b20e07345e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets evaluate transformers[sentencepiece] --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e80a9343-b1e0-43fa-ae35-c56a9dfa4568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu --quiet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce45c40c-3378-4021-8e56-f3f9568a49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9a15fe-8cf0-464b-b874-3af75a7da430",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An√°lisis de Sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8e9c026-d5f8-474a-9079-22a51b7da27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'NEG', 'score': 0.9434412717819214}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "\n",
    "resultado = classifier(\"Odio aprender sobre inteligencia artificial.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb5a1872-45be-48c5-8fe1-bcba7559e233",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POS', 'score': 0.9226016402244568}]\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"sentiment-analysis\", model=\"pysentimiento/robertuito-sentiment-analysis\")\n",
    "\n",
    "resultado = classifier(\"Amo aprender sobre inteligencia artificial.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faedeeff-e04a-4f10-993f-07a05b3359e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zero-Shot Classification (Clasificaci√≥n de texto en categor√≠as)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7809bfd-fb9a-47b1-bd4b-a759776b6803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sequence': 'La pol√≠tica es el arte de gobernar y organizar la vida en sociedad. A trav√©s de instituciones, leyes y decisiones, busca resolver conflictos, distribuir recursos y garantizar el bien com√∫n.', 'labels': ['pol√≠tica', 'educaci√≥n', 'negocios'], 'scores': [0.9916322827339172, 0.004312432371079922, 0.004055291414260864]}\n"
     ]
    }
   ],
   "source": [
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "resultado = classifier(\n",
    "    \"La pol√≠tica es el arte de gobernar y organizar la vida en sociedad. A trav√©s de instituciones, leyes y decisiones, busca resolver conflictos, distribuir recursos y garantizar el bien com√∫n.\",\n",
    "    candidate_labels=[\"educaci√≥n\", \"pol√≠tica\", \"negocios\"],\n",
    "    hypothesis_template=\"Este texto trata sobre {}.\"\n",
    ")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed8375d-0ff5-4a15-94fa-e231006dc19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generaci√≥n de texto "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc6811b-299f-48b6-8e36-79dca3411edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'En este curso aprender√°s sobre inteligencia artificial. Como ya sabr√°s, la mayor√≠a de los ordenadores pueden aprender sobre ordenadores basados en ordenadores, como ordenadores port√°tiles y ordenadores para crear aplicaciones inteligentes a partir de ordenadores. \\n\\nSin embargo, a ti te va la'}, {'generated_text': 'En este curso aprender√°s sobre inteligencia artificial. \\n\\n‚ÄîLo har√© si se me quita el sue√±o ‚Äîadvirti√≥ Klaus, algo sorprendido por la conversaci√≥n entre Julian y Julian. \\n\\n‚ÄîEs una idea magn√≠fica, pero tengo que decir algo. Julian tiene'}]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"DeepESP/gpt2-spanish\")\n",
    "\n",
    "resultado = generator(\n",
    "    \"En este curso aprender√°s sobre inteligencia artificial\",\n",
    "    max_length=50,\n",
    "    num_return_sequences=2\n",
    ")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78368ad0-70a0-4990-9b4a-d2e90a2437fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'En este curso aprender√°s sobre inteligencia artificial. \\n\\nLa clase de la ense√±anza est√° destinada a ser muy √∫til a un ni√±o. Puedes elegir de buen profesor o de maestro o de disc√≠pulo, para que puedas usar tu sistema inform√°tico. \\n\\nEs importante'}]\n"
     ]
    }
   ],
   "source": [
    "generator = pipeline(\"text-generation\", model=\"DeepESP/gpt2-spanish\")\n",
    "\n",
    "resultado = generator(\n",
    "    \"En este curso aprender√°s sobre inteligencia artificial\",\n",
    ")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1435936-5ab0-427f-9522-693f1c62ff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completar el texto con la palabra m√°s probable (Fill-Mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9e7b1db-22cb-4f7f-903f-784fae9e8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From üëâv4.50üëà onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'score': 0.08100215345621109, 'token': 3792, 'token_str': 'sociales', 'sequence': 'Este curso ense√±a sobre modelos sociales.'}, {'score': 0.06293947249650955, 'token': 6156, 'token_str': 'econ√≥micos', 'sequence': 'Este curso ense√±a sobre modelos econ√≥micos.'}, {'score': 0.027612948790192604, 'token': 3, 'token_str': '[UNK]', 'sequence': 'Este curso ense√±a sobre modelos.'}]\n"
     ]
    }
   ],
   "source": [
    "unmasker = pipeline(\"fill-mask\", model=\"dccuchile/bert-base-spanish-wwm-cased\")\n",
    "\n",
    "resultado = unmasker(\"Este curso ense√±a sobre modelos [MASK].\", top_k=3)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2b5b417-5bd6-48b7-acb9-8909e7505a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificar nombres propios en un texto (Entidades) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05725401-b2e3-415f-a6ab-8f1694ffdb50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at PlanTL-GOB-ES/roberta-base-bne and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n",
      "/home/ubuntu/env/lib/python3.12/site-packages/transformers/pipelines/token_classification.py:170: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"AggregationStrategy.SIMPLE\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'LABEL_0', 'score': np.float32(0.5211671), 'word': 'Me', 'start': 0, 'end': 2}, {'entity_group': 'LABEL_1', 'score': np.float32(0.54079884), 'word': ' llamo Pedro y trabajo en', 'start': 3, 'end': 27}, {'entity_group': 'LABEL_0', 'score': np.float32(0.510976), 'word': ' Telef√≥nica en Madrid.', 'start': 28, 'end': 49}]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"PlanTL-GOB-ES/roberta-base-bne\", grouped_entities=True)\n",
    "\n",
    "resultado = ner(\"Me llamo Pedro y trabajo en Telef√≥nica en Madrid.\")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea25c014-6944-4dbe-92cb-af2c823938c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at mrm8488/bert-spanish-cased-finetuned-ner were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'PER', 'score': np.float32(0.9989525), 'word': 'Pedro', 'start': 9, 'end': 14}, {'entity_group': 'ORG', 'score': np.float32(0.90264404), 'word': 'Telef√≥nica', 'start': 28, 'end': 38}, {'entity_group': 'LOC', 'score': np.float32(0.9998223), 'word': 'Madrid', 'start': 42, 'end': 48}]\n"
     ]
    }
   ],
   "source": [
    "ner = pipeline(\"ner\", model=\"mrm8488/bert-spanish-cased-finetuned-ner\", grouped_entities=True)\n",
    "resultado = ner(\"Me llamo Pedro y trabajo en Telef√≥nica en Madrid.\")\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ccd51-6143-4c99-9c0f-0acc6dc9cdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extraer respuestas a preguntas en un contexto dado (Question Answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7159d99-155d-42b5-9ffa-467f2c3ab954",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74e8ea057554d77aa024a96a8cf5e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189d27bc95e447beb4c353d62e4efd6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65dd36daca7f47f2a4fcb49c0087815d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3144f6b32c44c899f9acde25f18179d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/858k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d710f5f316d14e53b26a6a91d429c4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/516k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a519501898dc4ffeaea84ed5779742eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5aa98ef345249c7b626198927146470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a968b839869440ab82756818da96be87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.568343997001648, 'start': 25, 'end': 38, 'answer': 'en Telef√≥nica'}\n"
     ]
    }
   ],
   "source": [
    "qa = pipeline(\"question-answering\", model=\"PlanTL-GOB-ES/roberta-large-bne-sqac\")\n",
    "\n",
    "resultado = qa(\n",
    "    question=\"¬øD√≥nde trabajo?\",\n",
    "    context=\"Me llamo Pedro y trabajo en Telef√≥nica en Madrid.\"\n",
    ")\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c2f7e6-afc4-4259-828f-521b99cfcf40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resumen de Texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15e89ef8-1673-4b19-bcc9-032d025f63ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e552053ba241768fb447222f1d7324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/730 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6d50a2146447df81ff3b9a92c4dc63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c3a82e87ab4accb82fd3252f57a567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6187b12365974b38bc61e05d1ac2d13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0c478a204e49d3b4dcf782e160f0e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d2669835144d77941f696f817432ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "/home/ubuntu/env/lib/python3.12/site-packages/transformers/convert_slow_tokenizer.py:561: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Device set to use cpu\n",
      "Your max_length is set to 84, but your input_length is only 68. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=34)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'En los √∫ltimos a√±os, el n√∫mero de ingenieros en Estados Unidos ha disminuido.'}]\n"
     ]
    }
   ],
   "source": [
    "summarizer = pipeline(\"summarization\", model=\"csebuetnlp/mT5_multilingual_XLSum\")\n",
    "\n",
    "texto = \"\"\"\n",
    "Am√©rica ha cambiado dr√°sticamente en los √∫ltimos a√±os. No solo ha disminuido el n√∫mero \n",
    "de graduados en ingenier√≠a, sino que muchas universidades ahora se enfocan en ciencias aplicadas.\n",
    "China e India, en cambio, contin√∫an formando m√°s ingenieros.\n",
    "\"\"\"\n",
    "\n",
    "resultado = summarizer(texto)\n",
    "\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15934b4-ba48-4b8b-a785-635d0befbccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traducci√≥n de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a1d320-28d0-4b13-8042-437f208a4e26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
